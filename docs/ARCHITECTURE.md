# ğŸ—ï¸ System Architecture

## ğŸ“‹ Overview

The DD2410 TIAGo mobile manipulation system implements a hierarchical architecture combining behavior trees for reactive control and state machines for high-level task coordination. This design enables robust, adaptive robot behavior in dynamic environments.

## ğŸ¯ Design Principles

### 1. Modularity
- **Loosely Coupled Components**: Each module can be developed and tested independently
- **Interface Standardization**: ROS messages and services provide clean APIs
- **Plugin Architecture**: Behaviors can be easily added or modified

### 2. Reactivity
- **Behavior Trees**: Enable reactive responses to environmental changes
- **Event-Driven Design**: System responds to sensor data and external events
- **Graceful Degradation**: Failure in one component doesn't crash the entire system

### 3. Scalability
- **Hierarchical Organization**: High-level planning to low-level control
- **Parallel Execution**: Multiple behaviors can run simultaneously
- **Resource Management**: Efficient use of computational resources

## ğŸ›ï¸ System Layers

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    HIGH-LEVEL TASK PLANNER                 â”‚
â”‚                   (Mission Coordination)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  BEHAVIOR TREE EXECUTOR                    â”‚
â”‚              (Reactive Task Execution)                     â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚                     â”‚                         â”‚
â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ NAVIGATION â”‚      â”‚   PERCEPTION    â”‚      â”‚ MANIPULATION    â”‚
â”‚  MODULE    â”‚      â”‚     MODULE      â”‚      â”‚     MODULE      â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚                     â”‚                         â”‚
â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚PATH PLAN  â”‚      â”‚OBJECT DETECTION â”‚      â”‚ GRASP PLANNING  â”‚
â”‚OBSTACLE   â”‚      â”‚POSE ESTIMATION  â”‚      â”‚ MOTION CONTROL  â”‚
â”‚AVOIDANCE  â”‚      â”‚SCENE UNDERSTANDâ”‚      â”‚ FORCE CONTROL   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚                     â”‚                         â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  TIAGO ROBOT  â”‚
                    â”‚   PLATFORM    â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”§ Core Components

### 1. High-Level Task Planner

**Purpose**: Coordinates overall mission execution and resource allocation.

**Responsibilities**:
- Parse high-level commands (e.g., "pick up the red cup")
- Decompose tasks into actionable subtasks
- Monitor overall progress and handle mission-level failures
- Coordinate between different behavioral modules

**Implementation**:
```python
class TaskPlanner:
    def __init__(self):
        self.current_mission = None
        self.task_queue = []
        
    def execute_mission(self, mission_description):
        subtasks = self.decompose_mission(mission_description)
        for task in subtasks:
            self.behavior_tree.execute_task(task)
```

### 2. Behavior Tree Executor

**Purpose**: Provides reactive control architecture for robust task execution.

**Key Features**:
- **Compositional**: Complex behaviors built from simple primitives
- **Reactive**: Responds immediately to environmental changes
- **Transparent**: Easy to understand and debug behavior logic

**Node Types**:

#### Control Nodes
- **Sequence**: Execute children in order (AND logic)
- **Selector**: Try alternatives until success (OR logic)
- **Parallel**: Execute multiple children simultaneously

#### Leaf Nodes
- **Action Nodes**: Execute robot behaviors
- **Condition Nodes**: Check system/environment state

**Example Structure**:
```
NavigationTask
â”œâ”€â”€ Sequence
â”‚   â”œâ”€â”€ CheckBattery [Condition]
â”‚   â”œâ”€â”€ PlanPath [Action]
â”‚   â”œâ”€â”€ Parallel
â”‚   â”‚   â”œâ”€â”€ ExecutePath [Action]
â”‚   â”‚   â”œâ”€â”€ MonitorObstacles [Condition]
â”‚   â”‚   â””â”€â”€ UpdateLocalization [Action]
â”‚   â””â”€â”€ ValidateArrival [Condition]
```

### 3. Navigation Module

**Purpose**: Handles robot mobility and spatial reasoning.

**Components**:

#### Path Planning
- **Global Planner**: A* or RRT for long-range planning
- **Local Planner**: Dynamic Window Approach for reactive navigation
- **Recovery Behaviors**: Escape from local minima

#### Localization
- **AMCL**: Adaptive Monte Carlo Localization
- **Sensor Fusion**: Combine odometry, laser, and visual data
- **Map Management**: Load and update environmental maps

#### Obstacle Avoidance
- **Costmap**: Multi-layered obstacle representation
- **Dynamic Obstacles**: Real-time obstacle tracking
- **Safety Margins**: Conservative path planning

**ROS Nodes**:
```
navigation_module/
â”œâ”€â”€ global_planner_node
â”œâ”€â”€ local_planner_node
â”œâ”€â”€ amcl_node
â”œâ”€â”€ costmap_node
â””â”€â”€ recovery_behavior_node
```

### 4. Perception Module

**Purpose**: Interprets sensor data for environmental understanding.

**Capabilities**:

#### Object Detection
- **RGB-D Processing**: Combine color and depth information
- **Feature Extraction**: SIFT, ORB, or learned features
- **Object Classification**: Template matching or deep learning

#### Pose Estimation
- **6DOF Pose**: Full position and orientation estimation
- **Tracking**: Temporal consistency across frames
- **Uncertainty Estimation**: Confidence in pose estimates

#### Scene Understanding
- **Semantic Segmentation**: Classify scene elements
- **Spatial Relations**: Object-object relationships
- **Change Detection**: Identify environmental changes

**Processing Pipeline**:
```
Raw Sensor Data â†’ Preprocessing â†’ Feature Extraction â†’ 
Object Detection â†’ Pose Estimation â†’ Scene Graph â†’ 
High-Level Understanding
```

### 5. Manipulation Module

**Purpose**: Controls robot arm and end-effector for object manipulation.

**Subcomponents**:

#### Grasp Planning
- **Grasp Synthesis**: Generate candidate grasps
- **Grasp Selection**: Choose optimal grasp based on task
- **Force Planning**: Determine required grip forces

#### Motion Planning
- **MoveIt! Integration**: Industry-standard motion planning
- **Collision Avoidance**: Safe trajectory generation
- **Trajectory Optimization**: Smooth, efficient motions

#### Execution Control
- **Joint Control**: Low-level motor commands
- **Force Control**: Compliant manipulation
- **Error Recovery**: Handle execution failures

**Control Loop**:
```
Task Command â†’ Grasp Planning â†’ Motion Planning â†’ 
Trajectory Execution â†’ Force Control â†’ Success Verification
```

## ğŸ”„ Data Flow

### Sensor Data Flow
```
Hardware Sensors â†’ ROS Drivers â†’ Sensor Processing â†’ 
Feature Extraction â†’ State Estimation â†’ Behavior Tree
```

### Command Flow
```
High-Level Task â†’ Behavior Tree â†’ Module Commands â†’ 
ROS Actions/Services â†’ Hardware Controllers â†’ Robot Actuators
```

### Feedback Flow
```
Sensor Feedback â†’ State Monitoring â†’ Behavior Tree â†’ 
Task Adaptation â†’ New Commands
```

## ğŸš¦ State Management

### Global State
- **Robot Pose**: Current position and orientation
- **Battery Level**: Power management
- **System Health**: Component status monitoring

### Task State
- **Current Objective**: Active task description
- **Progress Tracking**: Completion percentage
- **Error Conditions**: Failure modes and recovery

### Environmental State
- **Object Locations**: Known object positions
- **Map Updates**: Dynamic environment changes
- **Obstacle Status**: Current obstacles and clearances

## ğŸ”§ Configuration Management

### Parameter Hierarchy
```
global_config/
â”œâ”€â”€ robot_parameters.yaml    # Physical robot specs
â”œâ”€â”€ navigation_config.yaml   # Navigation settings
â”œâ”€â”€ perception_config.yaml   # Sensor parameters
â”œâ”€â”€ manipulation_config.yaml # Arm/gripper settings
â””â”€â”€ behavior_config.yaml     # Behavior tree parameters
```

### Dynamic Reconfiguration
- **Runtime Tuning**: Adjust parameters during execution
- **Performance Optimization**: Adapt to different scenarios
- **Debug Support**: Enable/disable debug outputs

## ğŸ§ª Testing Architecture

### Unit Testing
- **Individual Behaviors**: Test each BT node
- **Module Interfaces**: Verify ROS communication
- **Algorithm Validation**: Mathematical correctness

### Integration Testing
- **Module Interaction**: Cross-module communication
- **End-to-End Scenarios**: Complete task execution
- **Performance Benchmarks**: Timing and resource usage

### Simulation Testing
- **Gazebo Scenarios**: Physics-based validation
- **Edge Cases**: Stress testing and failure modes
- **Regression Testing**: Ensure new changes don't break existing functionality

## ğŸ“Š Performance Characteristics

### Real-Time Requirements
- **Control Loop**: 10-50 Hz for low-level control
- **Perception Pipeline**: 5-10 Hz for object detection
- **Planning Cycle**: 1-5 Hz for high-level planning

### Resource Utilization
- **CPU Usage**: Distributed across multiple cores
- **Memory Footprint**: ~2-4 GB typical usage
- **Network Bandwidth**: Inter-node communication overhead

### Scalability Metrics
- **Task Complexity**: Linear scaling with behavior tree size
- **Environment Size**: Logarithmic scaling with map size
- **Object Count**: Linear scaling with tracked objects

## ğŸ›¡ï¸ Error Handling Strategy

### Fault Detection
- **Sensor Validation**: Check data consistency
- **Timeout Monitoring**: Detect unresponsive components
- **Performance Degradation**: Monitor system health

### Recovery Mechanisms
- **Behavior Tree Recovery**: Built-in fallback behaviors
- **Component Restart**: Automatic service recovery
- **Graceful Degradation**: Reduced functionality modes

### Logging and Diagnostics
- **Structured Logging**: Hierarchical log levels
- **Performance Metrics**: Real-time monitoring
- **Debug Visualization**: RViz-based debugging tools

## ğŸš€ Future Extensions

### Planned Enhancements
- **Machine Learning Integration**: Replace rule-based components
- **Multi-Robot Coordination**: Distributed task execution
- **Natural Language Interface**: Voice-based commands
- **Adaptive Behaviors**: Learning from experience

### Research Directions
- **Semantic Understanding**: Deeper scene comprehension
- **Predictive Planning**: Anticipate environmental changes
- **Explainable AI**: Interpretable decision making
- **Sim-to-Real Transfer**: Reduce reality gap

---

This architecture provides a solid foundation for complex mobile manipulation tasks while maintaining flexibility for future enhancements and research directions. 